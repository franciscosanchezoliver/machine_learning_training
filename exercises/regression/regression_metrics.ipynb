{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6517513a-f7da-4ff7-baf4-a636fce0932b",
   "metadata": {},
   "source": [
    "# Analyzing Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c06ca9-be92-492f-b69e-20b1e9f1a1d6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Regression is a foundational __tool in machine learning for predicting continuous variables__. Accurately __evaluating regression models is crucial to ensure their performance and reliability__. This document explores __common regression metrics__, their calculations, and their practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3dfdf5-aae5-49d1-8ce6-7130e2219822",
   "metadata": {},
   "source": [
    "# Data and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753e823-b8da-41bb-aa1b-3f340b71a7af",
   "metadata": {},
   "source": [
    "## Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f814ee6-6393-484b-8748-c4007d1df79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012de62b-701c-46de-b3e0-9d9998728cba",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We use the California Housing dataset from sklearn, which provides housing-related features and median house values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cf430e-d406-4a90-bef2-ff8c6bf7807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data \n",
    "data = fetch_california_housing()\n",
    "\n",
    "# Getting the features and the target as Dataframes \n",
    "features_df = pd.DataFrame(data[\"data\"], columns = data.feature_names)\n",
    "target_df = pd.DataFrame(data[\"target\"], columns = data.target_names)\n",
    "\n",
    "# Merging both the features and the target into the same dataframe\n",
    "housing_df = pd.concat( \n",
    "    [features_df, target_df],\n",
    "    axis = 1 # Horizontally\n",
    ")\n",
    "\n",
    "# The target variable is express in hundreds of thousands, but \n",
    "# I would like to have the original value in the target variable\n",
    "housing_df[\"MedHouseVal\"] = housing_df[\"MedHouseVal\"] * 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990492cf-5546-4c98-be6d-5bbcc95afe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 20640\n",
      "Columns: 9\n",
      "Target: MedHouseVal\n",
      "Features (8):\n",
      " - MedInc\n",
      " - HouseAge\n",
      " - AveRooms\n",
      " - AveBedrms\n",
      " - Population\n",
      " - AveOccup\n",
      " - Latitude\n",
      " - Longitude\n",
      "\n",
      "Example:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23     452600.0  \n",
       "1    -122.22     358500.0  \n",
       "2    -122.24     352100.0  \n",
       "3    -122.25     341300.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Rows: {housing_df.shape[0]}\")\n",
    "print(f\"Columns: {housing_df.shape[1]}\")\n",
    "\n",
    "print(\"Target:\", data.target_names[0])\n",
    "\n",
    "print(f\"Features ({len(data.feature_names)}):\")\n",
    "for feature in data.feature_names:\n",
    "    print(\" -\", feature)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "example_nrows = 4\n",
    "print(f\"Example:\")\n",
    "housing_df.head(example_nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596bb1c-f89f-42f7-8d20-89087203579c",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Data is split into 80% training and 20% testing for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa4891a-e9b3-46f8-ad60-67d313ee4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data set:  16512\n",
      "Test data set:  4128\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    housing_df,\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train data set: \",  train_df.shape[0])\n",
    "print(\"Test data set: \", test_df.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c4fbc25-d353-4487-ad59-d4c9e9943b1a",
   "metadata": {},
   "source": [
    "# Regression Models\n",
    "\n",
    "Just to test how different models get a different score, we are going to use a Linear Regression Model and a Random Forest model.\n",
    "\n",
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceadeaab-2514-4c4f-9764-17b29ccdd057",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, \n",
    "    test_size=0.2, \n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142cc217-c2ae-4ad9-b510-6b7c0cc8f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regression_model = LinearRegression()\n",
    "linear_regression_model.fit(\n",
    "    X_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4296c-8a12-4be9-a3c7-e2c96a291512",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = linear_regression_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396f0c7-8565-47be-a4c9-b7db672c6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R^2 = \" , r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7212d28-830a-4451-88f5-66212e9ced37",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = linear_regression_model.predict( train_df[data.feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff4cf1-1f60-4e35-8a71-176e4ff48f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_model_df = LinearRegression()\n",
    "linear_regression_model_df.fit(train_df, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76bb66-ade1-4da9-a711-d35ae70a9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847108e-71f5-4f01-8bad-03a13b90b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e098d-dcd5-4421-a814-3af879e8b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_df[data.feature_names], train_df[data.target_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce26fb3-2385-464a-ba09-6c2ecb344d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"predicted_lr_train\"] = lr.predict(train_df[data.feature_names])\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55a0b6-f590-426a-8174-ad4408aa90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"difference_train\"] = train_df[\"MedHouseVal\"] - train_df[\"predicted_lr_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ae321-2626-4f71-b8ef-63d358501530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"difference_squared_train\"] = train_df[\"difference_train\"] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a3adee-699c-4215-8de3-7a3ae66a7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864d877-358e-4c87-9f93-1429835465c2",
   "metadata": {},
   "source": [
    "# $ R^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872419db-ad31-42f2-b9fe-aa6aad9044f7",
   "metadata": {},
   "source": [
    "## How to calculate it\n",
    "\n",
    "The $ R^2 $ formula is defined as follows: \n",
    "\n",
    "$ R^2 =  1 - \\frac{ SS_{res} }{ SS_{tot} }  $\n",
    "\n",
    "Where:\n",
    "- $ SS_{res} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2  $\n",
    "- $ SS_{tot} = \\sum_{i=1}^{n} (y_i - \\bar{y_i})^2  $\n",
    "    - $ {y_i} $: Real Value\n",
    "    - $ \\hat{y_i} $: Predicted value \n",
    "    - $ \\bar{y_i} $: Mean of observed values\n",
    "\n",
    "Meaning:\n",
    "- $ SS_{res} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2  $ (Residuals sum of squares)\n",
    "- $ SS_{tot} = \\sum_{i=1}^{n} (y_i - \\bar{y_i})^2  $ (Residuals considering the mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2100c1-483a-4c22-875b-c3a9920bb490",
   "metadata": {},
   "source": [
    "## Example with a small table\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "Observed (y) & Predicted (\\hat{y}) & Error (y - \\hat{y}) \\\\ \n",
    "\\hline\n",
    "5.0 & 4.8 & 0.2 \\\\ \n",
    "\\hline\n",
    "7.0 & 6.5 & 0.5 \\\\ \n",
    "\\hline\n",
    "4.0 & 4.2 & -0.2 \\\\ \n",
    "\\hline\n",
    "\\end{array}\n",
    "$$ \n",
    "\n",
    "\n",
    "$ SS_{res} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 $\n",
    "$ = (5-4.8)^2 + (7-6.5)^2 + (4 - 4.2)^2 $\n",
    "$ = 0.04 + 0.25 + 0.04 $\n",
    "$ = 0.33 $\n",
    "\n",
    "To calculate $ SS_{tot} $ we need to first calculate the mean ($ \\bar{y} $). So let's calculate the mean: \n",
    "$$ \\bar{y} = \\frac{5 + 7 + 4}{3} = \\frac{16}{3} = 5.33 $$\n",
    "\n",
    "Now, we can calculate the $ SS_{tot} $ \n",
    "\n",
    "$ SS_{tot} = \\sum_{i=1}^{n} (y_i - \\bar{y_i})^2  $ \n",
    "$ = (5 - 5.33)^2 + (7 - 5.33)^2 + (4 - 5.33)^2  $ \n",
    "$ =  0.1089 + 2.7889 + 1.7689$ \n",
    "$ =  4.67 $ \n",
    "\n",
    "Now that we have both terms calculated ( $ SS_{res} $ and $ SS_{tot} $ ) we can calculate $ R^2 $\n",
    "\n",
    "$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} $ \n",
    "$ = 1 - \\frac{0.33}{4.67} $ \n",
    "$ = 1 - 0.07 $ \n",
    "$ = 0.93 $\n",
    "\n",
    "So we can say that the model explains approximately 93% of the variance in the observed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388680f-1bd4-40bf-8a15-4d4e29792d67",
   "metadata": {},
   "source": [
    "## $ R^2 $ in the training set\n",
    "\n",
    "Now we want to calculate the value of $ R^2 $ applied to our training set. This means that we have used our machine learning model to predict on our train set (this doesn't make much sense because the model has been trained with the training set) but we can do this later on the test set and compare both results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae9ffd-bf7c-49cc-a50b-f41de6537e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a90435-86a1-4769-bf00-12c8dff64541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the mean of the observed values\n",
    "mean_observed_values = np.mean(train_df[\"MedHouseVal\"])\n",
    "print(f\"Mean of the house price: {mean_observed_values }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a81034-7ca0-4025-aa7d-faac5717e54e",
   "metadata": {},
   "source": [
    "Now, let's calculate the term: $ SS_{tot} = \\sum_{i=1}^{n} (y_i - \\bar{y_i})^2  $ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8a0e1-3f02-40cf-b7c2-3b756914efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"SS_tot\"] =  (train_df[\"MedHouseVal\"] - mean_observed_values)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ed137-0d31-4336-8766-bea2fb4b7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_tot = train_df[\"SS_tot\"].sum()\n",
    "print(f\"SS_tot term: {ss_tot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312bd8ad-15cd-4dad-8405-92f6dede0fb2",
   "metadata": {},
   "source": [
    "Now, let's calculate the - $ SS_{res} = \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2  $ (Residuals sum of squares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa104-4bf1-4449-9e9e-a75a601194a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"SS_res\"] = (train_df[\"MedHouseVal\"] - train_df[\"predicted_lr_train\"]) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24651a12-64a8-403e-9bfd-3c3c11149926",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_res = train_df[\"SS_res\"].sum()\n",
    "print(f\"SS_res term: {ss_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467b0fe-9b12-43db-94ea-3bbad602bb48",
   "metadata": {},
   "source": [
    "\n",
    "$ R^2 =  1 - \\frac{ SS_{res} }{ SS_{tot} }  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa5970-c166-4b25-bc7c-87a607adee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "print(f\"R squared: {r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d5ae6-d694-410b-9bc0-5da6c717bd1b",
   "metadata": {},
   "source": [
    "We should get the same result if we use the built in function in the linear regression model \"score\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a51288-9c72-4bc9-a0ca-e8786061a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(train_df[data.feature_names], train_df[data.target_names])\n",
    "score_sklearn = linear_regression.score(train_df[data.feature_names], train_df[data.target_names])\n",
    "print(f\"Score (R^2) calculated with sklearn built in function: {score_sklearn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354dbc2-b65a-455a-8ed8-29319a47f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "R squared: \n",
    "     Self calculated: {r_squared}\n",
    "  Sklearn calculated: {score_sklearn}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8db2b-35dc-4df1-b4d7-45c6c7315183",
   "metadata": {},
   "source": [
    "As we can see its the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab2ab6-29c9-4f7c-84d2-57dd2087c49e",
   "metadata": {},
   "source": [
    "Now we can try to our model to predict with unseen data (test set), and check how much $R^2$ we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82308f6-1263-4e9c-9f25-eab196b546b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_with_test_set = linear_regression.score(test_df[data.feature_names], test_df[data.target_names])\n",
    "print(f\"R^2 obtained on the test set: {r_squared_with_test_set}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159962ec-525c-477b-a07c-b2f62f6d423b",
   "metadata": {},
   "source": [
    "## Is our model good?\n",
    "\n",
    "This depends on the context of our data and the specific of the domain we're working in. \n",
    "However, there are some general guidelines:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06959e-9b21-4936-b70e-0b4e68018130",
   "metadata": {},
   "source": [
    "### General Interpretation\n",
    "- $R^2$ = 1 => __Perfect fit__. The model explains 100% of the variance in the dependent variable.\n",
    "- $R^2$ = 0 => __The model explains none of the variance.__\n",
    "- $R^2$ < 0 (Negative) => __The model performs worse than a simple horizontal line__ (mean of the data). This indicates a poorly fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291bfa5c-89be-4af3-9f3b-dff228a75da6",
   "metadata": {},
   "source": [
    "### Typical Ranges in Practice\n",
    "1. __High__ $R^2$ (__0.7 to 1.0__):\n",
    "    - Indicates the __model explains a large portion of the variance.__\n",
    "    - Often seen in __controlled experiments or well-understood domains, like physics__.\n",
    "  \n",
    "2. __Moderate__ $R^2$ (__0.4 to 0.7__):\n",
    "    - Common in __fields like social sciences, biology, or economics.__\n",
    "    - Is __acceptable if the data is inherently noisy or complex__.\n",
    "\n",
    "3. __Low__ $R^2$ (__< 0.4)__:\n",
    "    - Indicates the model has __limited explanatory power.__\n",
    "    - Can be __acceptable in domains where many unmeasured factors influence the outcome (e.g. human behaviour studies).__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2f1ad-6fe9-4825-ab2e-c3620814dc05",
   "metadata": {},
   "source": [
    "### Training vs Test\n",
    "- __Training__ $R^2$: Measures fit on the data the model was trained on. __Higher scores are expected__.\n",
    "- __Test__ $R^2$: Measures __generalization to unseen data__. If this __value is significantly lower that in the training, it might indicate overfitting.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0135324a-1647-4b4f-86ea-d87876cb0f28",
   "metadata": {},
   "source": [
    "### Final Thoughs\n",
    "1. __Compare $R^2$ against Benchmarks__: __Use domain-specific benchmarks or baseline models__. For instance, __compare $R^2$ with a simple linear regression__ model __or a previous model__ in the same task.\n",
    "    \n",
    "2. Consider Adjusted $R^2$:\n",
    "    - Ensure the model ins't artificially inflating $R^2$ by adding irrelevant predictors.\n",
    "    \n",
    "3. Domain Expectations:\n",
    "    - A \"good\" $R^2$ in physics might be 0.9 but in social sciences, 0.3 might be impressive due to data variability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b487c6-31a1-44ea-aed9-8910223afda0",
   "metadata": {},
   "source": [
    "## $R^2$ Summary\n",
    "- __Easy to interpret__ as __percentage of explained variance__.\n",
    "- __Can be artificially inflated with useless variables__: new variables can either do nothing or explain more.\n",
    "- Does not really tell us if the model is good or bad, models can have a high $R^2$ but still have large residuals (errors) => Explain most of the variance, but predictions still far off in absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797fd5c-4eca-4fe5-8e78-6738bbcecde4",
   "metadata": {},
   "source": [
    "# Adjusted $R^2$\n",
    "\n",
    "$ R^2_{adj} = 1 - (1 - R^2) \\frac{n - 1}{n - p - 1}  $\n",
    "\n",
    "Where:\n",
    "- p: Number of variables, so the more variables you add the bigger is the denominator (penalizes a lot of variable).\n",
    "- n: Sample size. \n",
    "\n",
    "With this formula, we are \"fixing\" the problem that the $R^2$ has (artificially increase if we add more variable, even if the variables are useless). We do this by penalizing the number of variables that we have into account. \n",
    "\n",
    "As we can see in the formula, before calculating the $R^2_{adj}$ we need to calculate $R^2$ as it is one of the terms of the formula.\n",
    "\n",
    "$R^2_{adj}$ can be negative, and it is always less than or equal to $R^2$. Unlike $R^2$, the $R^2_{adj}$ increases only when the increase of $R^2$ is more than one would expect by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc08591-9024-4277-91f9-0314cd866fca",
   "metadata": {},
   "source": [
    "$R^2_{adj}$ Summary\n",
    "\n",
    "- Penalizes unnecessary complexity (number of predictors)\n",
    "- Better for comparing models with different number of variables (will only improve with usefull variables).\n",
    "- Use $R^2$ and $R^2_{adj}$ in combination with other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8860c67-416c-4954-b8fa-de1dc060e842",
   "metadata": {},
   "source": [
    "Sklearn doesn't have a function to calculate $R^2_{adj}$ so we have to do the formula ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbf70b-43c9-4405-9ad5-582f6f6b37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the R^2 that we got in the model\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc512d6-065a-40d0-a089-40fc5e18eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows, columns = train_df.shape[0], train_df.shape[1]\n",
    "n = number_of_rows\n",
    "# The train dataset includes the target variable, so to get only the features we need\n",
    "# to substract 1\n",
    "p = columns - 1 \n",
    "\n",
    "print(f\"rows (n): {n}\")\n",
    "print(f\"features (p): {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a84f81-77d7-49cb-ae3f-caa210b95a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_adjusted = 1 - (1 - r_squared) * ( (n - 1) / (n - p - 1) )\n",
    "print(f\"\"\"\n",
    "r^2: {r_squared}\n",
    "r^2_adjusted: {r_squared_adjusted}\n",
    "difference (r^2 - r^2_adjusted): {r_squared - r_squared_adjusted}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1426b4-bd98-4aa4-b7d3-f9052aaf3159",
   "metadata": {},
   "source": [
    "# Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e842ea5-c950-4f65-b220-09bd962b9f9a",
   "metadata": {},
   "source": [
    "## MSE (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbfab0e-f611-4a03-9d4e-365a3928b308",
   "metadata": {},
   "source": [
    "$ \\frac{1}{n} \\sum^{a}_{i=1} (y_{i} - \\hat{y}_{i})^2$\n",
    "\n",
    "where: \n",
    "- $y_{i} - \\hat{y}_{i}$: is the difference between the real value and the prediction done. We squared this term to avoid negative numbers.\n",
    "\n",
    "What we are doing here is calculating the difference between the predicted value and the actual value, and summing up all this differences. \n",
    "- __Not very intuitive__ because as we have squared the differences, the output is not in the original scale (RMSE has the scale of the original measure).\n",
    "- __Emphasizes large errors__ due to the squaring, useful when larger errors are unacceptable.\n",
    "- __Useful in optimization algorithms__.\n",
    "- __Good when trying to minimize overall error__ in the model.\n",
    "- Highly __sensitive to outliers__.\n",
    "- __Scale-Dependent__ (depends on the scale of the features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b7902-9b45-4891-af24-4d5c4bf1b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imaging that we have the following data:\n",
    "true_values = [3, -0.5, 2, 7]\n",
    "predicted_values = [2.5, 0.0, 2, 8]\n",
    "\n",
    "# Let's calculate the MSE manually \n",
    "difference_between_real_and_predicted = np.array(true_values) - np.array(predicted_values)\n",
    "squared_differences = difference_between_real_and_predicted ** 2\n",
    "sum_squared_diffences = np.sum(squared_differences)\n",
    "mse = 1/len(true_values) * sum_squared_diffences \n",
    "\n",
    "print(f\"Difference between real and predicted: {difference_between_real_and_predicted}\")\n",
    "print(f\"Squared differences: {squared_differences}\")\n",
    "print(f\"Sum Squared Differences: {sum_squared_diffences}\")\n",
    "print(f\"MSE:{mse}\")\n",
    "\n",
    "# We can also use sklearn to calculate the MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_sklearn = mean_squared_error(\n",
    "    np.array(true_values),\n",
    "    np.array(predicted_values)\n",
    ")\n",
    "print(f\"MSE (with sklearn): {mse_sklearn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2da23e-a587-456d-878a-99af4a9425d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47349f55-e8c4-4ed1-aec7-680451f33709",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = np.array(true_values)\n",
    "predicted_values = np.array(predicted_values)\n",
    "residuals = true_values - predicted_values\n",
    "print(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6afcac-0a37-4991-a2df-8bd874670350",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f232b-edb7-4da2-b402-f2a212eb6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can represent graphically the differences between the real\n",
    "# and predicted values\n",
    "def show_true_and_predicted(\n",
    "    true_values, \n",
    "    predicted_values\n",
    "):\n",
    "    \"\"\"\n",
    "    Show in a graph the true vs predicted\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an array as long as the number of data points\n",
    "    x = np.arange(len(true_values))\n",
    "    \n",
    "    plt.scatter(\n",
    "        x, true_values, color=\"blue\", label=\"True Values\", marker= \"v\"\n",
    "    )\n",
    "    \n",
    "    plt.scatter(\n",
    "        x, predicted_values, color=\"red\", label=\"Predicted Values\"\n",
    "    )\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "show_true_and_predicted(true_values, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9213e40-789e-41df-9e88-e6c64a0e0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rows = train_df[[\"MedHouseVal\", \"predicted_lr_train\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a46514-36b3-4862-b9a3-ef1d8a1abb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b83d41-1af1-4a8c-a90d-63ec612d9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use the training set to calculate the MSE\n",
    "mse_training = 1/train_df.shape[0] *  np.sum(train_df[\"difference_squared_train\"])\n",
    "print(f\"MSE training: {mse_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c16d4-bd16-4d3c-88ab-54c997ffd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_training = mse_training ** 1/2\n",
    "print(f\"RMSE training:{rmse_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e020db8-0499-4beb-b940-28db860205dc",
   "metadata": {},
   "source": [
    "## RMSE (Root Mean Squared Error)\n",
    "\n",
    "$ \\sqrt{MSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }  $\n",
    "\n",
    "- __Same units as response variable__, therefore __easy to interpret__.\n",
    "- __Penalizes larger error due to squaring__.\n",
    "- __Good when trying to minimize overall error in the model__.\n",
    "- __Sensitive to outliers__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622d9dc-a5e1-4d8f-8548-14ac2aa0d4d2",
   "metadata": {},
   "source": [
    "## MAE (Mean Absolute Error)\n",
    "\n",
    "$ \\frac{1}{n} \\sum_{i=1}^{n} {|(y_i - \\hat{y_i})|} $\n",
    "\n",
    "- Measures how wrong predictions were on average in original units, therefore its easy to understand for humans => \"On average our model misses the correcty value by X\"\n",
    "- Less sensitive to outliers than MSE and RMSE\n",
    "- Does not penalize large errors as heavily.\n",
    "- Not differentiable at zero, which can affect some optimization methods => we cannot use MAE for some optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8857d-98d3-44f8-8d5c-9ada4f3cdaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imaging that we have the following data:\n",
    "true_values = [3, -0.5, 2, 7]\n",
    "predicted_values = [2.5, 0.0, 2, 8]\n",
    "\n",
    "manually_calculated_mae = 1/len(true_values)* sum(abs(np.array(true_values) - np.array(predicted_values)))\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "sklearn_calculated_mae =  mean_absolute_error(true_values, predicted_values)\n",
    "\n",
    "print(f\"Manually calculated MAE: {manually_calculated_mae}\")\n",
    "print(f\"Sklearn calculated MAE: {sklearn_calculated_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f42506-ddfd-4629-ada4-0e818472d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manually_MAE(true_values, predicted_values):\n",
    "    return 1/len(true_values)* sum(abs(np.array(true_values) - np.array(predicted_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcb904-8962-4007-a29b-d8ad7cc512bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we calculated the MAE to our training set\n",
    "print(manually_MAE(train_df[\"MedHouseVal\"].values, train_df[\"predicted_lr_train\"].values))\n",
    "print(mean_absolute_error(train_df[\"MedHouseVal\"].values, train_df[\"predicted_lr_train\"].values))\n",
    "\n",
    "print(f\"\"\"On average our model the correct value by {manually_MAE(train_df[\"MedHouseVal\"].values, train_df[\"predicted_lr_train\"].values)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e830c-a80f-44bb-aeec-e54b4340dd7d",
   "metadata": {},
   "source": [
    "## MAPE (Mean Absolute Percentage Error)\n",
    "\n",
    "$ \\frac{1}{n} \\sum_{i=1}^{n} |\\frac{(y_i - \\hat{y}_i)}{y_i}| $\n",
    "\n",
    "- Expresses errors as percentages, making iterpretability better.\n",
    "- Usefull when comparing forecast accuracy between datasets.\n",
    "- Undefined when actual values are zero or near zero (denominator 0 is the fraction).\n",
    "\n",
    "Here we don't have the actual units, but we have on average how much error in terms of percentage. \n",
    "\n",
    "This makes it more interpretable oftentimes, but also more useful when it comes to comparing it with other datasets or across datasets, because then it doesn't really matter \n",
    "what units ir or what the scale is, is about the percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be1414-4cb1-4924-b56c-1d939def2eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imaging that we have the following data:\n",
    "true_values = [3, -0.5, 2, 7]\n",
    "predicted_values = [2.5, 0.0, 2, 8]\n",
    "\n",
    "manually_calculated_mape = 1/len(true_values)* sum(abs((np.array(true_values) - np.array(predicted_values)) / np.array(true_values)))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "sklearn_calculated_mape =  mean_absolute_percentage_error(true_values, predicted_values)\n",
    "\n",
    "print(f\"Manually calculated MAPE: {manually_calculated_mape}\")\n",
    "print(f\"Sklearn calculated MAPE: {sklearn_calculated_mape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0479fb-7052-4eb0-8693-9e584d3d11f5",
   "metadata": {},
   "source": [
    "## MedAE (Median Absolute Error)\n",
    "$ MedAE = median(|y_i - y_i^2|) $\n",
    "\n",
    "- Robust to outliers.\n",
    "- Reflects typical magnitude of errors.\n",
    "- May not capture effect of large errors.\n",
    "- Less sensitive to overall error distribution\n",
    "\n",
    "This is the same idea, but instead of taking the average, we take median values, of course this is much more robust when it comes to outliers, but in general it doesn't really capture any effect of large errors or outliers, it is really not sensitive to the error distribution because it doesn't really matter what's happening left and right, the important thing is what's in the center. In the center is located my typical magnitude of error and that's what I'm interest in, but wer're not understanding anything about the error distribution, maybe there is some huge error that I'm not seeing because I'm just looking at the median absolute error so that's of course a blind spot, but its more robuts to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6813af-4010-4f06-8a18-f2e058a639fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baaf418-0052-41af-b178-b44b3aa1b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imaging that we have the following data:\n",
    "true_values = [3, -0.5, 2, 7]\n",
    "predicted_values = [2.5, 0.0, 2, 8]\n",
    "\n",
    "manually_calculated_medae = np.median(abs(np.array(true_values) - np.array(predicted_values)))\n",
    "\n",
    "sklearn_calculated_medae =  median_absolute_error(true_values, predicted_values)\n",
    "\n",
    "print(f\"Manually calculated MedAE: {manually_calculated_medae }\")\n",
    "print(f\"Sklearn calculated MedAE: {sklearn_calculated_medae }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc91af6-8c71-444e-9d45-25b54aad0211",
   "metadata": {},
   "source": [
    "## Honorable Mentions\n",
    "- MSLE (Mean Squared Logaritmic Error).\n",
    "- RMSLE (Root Mean Squared Logaritmic Error).\n",
    "- Explained Variance Score.\n",
    "- Symmetric MAPE (Mean Absolute Percentage Error).\n",
    "- Huber Loss.\n",
    "- AIC and BIC (Akaike and Bayes Information Criteria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf090e79-abfb-41ab-bf0c-79084e070366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
